# coach_agent/services/summarizer.py
import yaml
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from services.llm import get_llm 

def create_session_summary(
    messages: list[BaseMessage], 
    current_week: int,
    title: str,             # [ì¶”ê°€] ì¸ìë¡œ ë°›ìŒ
    exit_criteria: dict     # [ì¶”ê°€] ì¸ìë¡œ ë°›ìŒ (dict ê·¸ëŒ€ë¡œ ë°›ì•„ì„œ ë‚´ë¶€ì—ì„œ í¬ë§·íŒ…)
) -> str:
    
    # 1. ë©”ì‹œì§€ ì „ì²˜ë¦¬ (Transcript ìƒì„±)
    chat_transcript = ""
    for msg in messages:
        if isinstance(msg, HumanMessage):
            chat_transcript += f"User: {msg.content}\n"
        elif isinstance(msg, AIMessage):
            chat_transcript += f"Counselor: {msg.content}\n"
    
    if not chat_transcript:
        return ""

    # 2. Exit Criteriaë¥¼ ë³´ê¸° ì¢‹ì€ ë¬¸ìì—´(YAML)ë¡œ ë³€í™˜
    exit_criteria_str = yaml.dump(exit_criteria, allow_unicode=True, default_flow_style=False)

    # 3. PromptTemplate ì •ì˜
    summary_prompt = ChatPromptTemplate.from_template("""
    ë‹¤ìŒì€ {current_week}ì£¼ì°¨ ìƒë‹´ ë‚´ìš©ì…ë‹ˆë‹¤.
    ì˜¤ëŠ˜ ìƒë‹´ ì£¼ì œê°€ '{title}'ì¼ ë•Œ, ì•„ë˜ ì„¸ ê°€ì§€ í•­ëª©ì„ ì´ëª¨ì§€ë¥¼ í™œìš©í•œ ê°œì¡°ì‹ bullet í˜•íƒœë¡œ ëª…í™•í•˜ê²Œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
    ë¬¸ì¥ ìˆ˜ ì œí•œì€ ì—†ìŠµë‹ˆë‹¤. ë‹¨, ê° í•­ëª©ë³„ë¡œ í•„ìš”í•œ ì •ë³´ê°€ ë¹ ì§ì—†ì´ ë‹´ê¸°ë„ë¡ í•´ì£¼ì„¸ìš”.

    [ëŒ€í™” ë‚´ìš©]
    {chat_transcript}

    [ìš”ì•½ ì§€ì‹œì‚¬í•­]

    1. ğŸ§© **í•µì‹¬ ë‚´ìš© ìš”ì•½**
       - ì˜¤ëŠ˜ ìƒë‹´ ì£¼ì œì¸ '{title}'ê³¼ ì§ì ‘ì ìœ¼ë¡œ ì—°ê²°ë˜ëŠ” í•µì‹¬ ëŒ€í™” ë‚´ìš©ì„ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
       - ì‚¬ìš©ì ê´€ì ì—ì„œ ë¬´ì—‡ì„ ì´ì•¼ê¸°í–ˆê³ , ì–´ë–¤ í†µì°°ì´ ë‚˜ì™”ëŠ”ì§€ ëª…í™•í•˜ê²Œ ì •ë¦¬í•´ ì£¼ì„¸ìš”.

    2. ğŸ¯ **Exit Criteria ì¶©ì¡± ë¶„ì„**
       - ì´ë²ˆ ì£¼ì°¨ ìƒë‹´ì˜ ì¢…ë£Œ ê¸°ì¤€(exit criteria):
    {exit_criteria_str}
       
       - ì‚¬ìš©ìê°€ ëŒ€í™” ì¤‘ exit criteriaì˜ ê° í•­ëª©ì„ ì–´ë–»ê²Œ ì¶©ì¡±í–ˆëŠ”ì§€, ì•„ë˜ í˜•ì‹ìœ¼ë¡œ JSON-like bulletë¡œ ë¶„ì„í•´ ì£¼ì„¸ìš”.
       - ì˜ˆì‹œ í˜•ì‹:
         - `{{'ìë™ì‚¬ê³  ë¶„ì„': 'í• ì¸ì„ ë³´ë©´ ë§ˆìŒì´ ì¡°ê¸‰í•´ì ¸ ë¹¨ë¦¬ ì‚¬ì•¼ í•  ê²ƒë§Œ ê°™ë‹¤.'}}` 
       - ë°˜ë“œì‹œ **ê° exit criteria í•­ëª©ë³„ë¡œ í•˜ë‚˜ì”©** ì‚¬ìš©ìì˜ ì‹¤ì œ ë°œí™”ë¥¼ ê·¼ê±°ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

    3. ğŸ“ **ì˜¤ëŠ˜ ì‚¬ìš©ìê°€ í•©ì˜í•œ ê³¼ì œ**
       - ì‚¬ìš©ìê°€ ì˜¤ëŠ˜ ì„¸ì…˜ì—ì„œ ìŠ¤ìŠ¤ë¡œ ì§€í‚¤ê¸°ë¡œ í•œ í–‰ë™, ì—°ìŠµ ê³¼ì œ, ì²´í¬ë¦¬ìŠ¤íŠ¸ ë“±ì„ ì •ë¦¬í•´ ì£¼ì„¸ìš”.
       - ì‹¤í–‰ ë‹¨ê³„ê°€ í•œëˆˆì— ë³´ì´ë„ë¡ êµ¬ì²´ì ìœ¼ë¡œ bullet í˜•íƒœë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”.

    [ìš”ì•½]
    """)

    # 4. LLM í˜¸ì¶œ
    llm = get_llm()
    
    # chain = prompt | llm
    chain = summary_prompt | llm
    
    response = chain.invoke({
        "current_week": current_week,
        "title": title,
        "chat_transcript": chat_transcript,
        "exit_criteria_str": exit_criteria_str
    })
    
    return response.content