# coach_agent/graph/counsel_nodes.py

from __future__ import annotations
from typing import Dict, Any, List
from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage, RemoveMessage
from coach_agent.graph.state import State
from coach_agent.prompts.identity import PERSONA
from coach_agent.services.llm import TECHNIQUE_SELECTOR, LLM_CHAIN, CHAT_LLM
from coach_agent.utils.protocol_loader import load_techniques_catalog
from coach_agent.rag.search import search_cbt_corpus  # â† ë„¤ RAG ëª¨ë“ˆì— ë§ê²Œ import ìˆ˜ì •

# === summarizing helpers ===
def _serialize_recent_messages(
    messages: List[BaseMessage],
    max_turns: int = 6,
) -> str:
    """
    í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ìœ„í•œ 'ìµœê·¼ ëŒ€í™” ìš”ì•½ í…ìŠ¤íŠ¸' ìƒì„±.
    - ì „ì²´ íˆìŠ¤í† ë¦¬ë¥¼ ê±´ë“œë¦¬ì§€ ì•Šê³ , ë§ˆì§€ë§‰ max_turns ê°œë§Œ í…ìŠ¤íŠ¸ë¡œ ì§ë ¬í™”
    - Human/AI ì¤‘ì‹¬ìœ¼ë¡œ role ë¼ë²¨ì„ ë¶™ì—¬ì¤€ë‹¤.
    """
    if not messages:
        return ""

    sub = messages[-max_turns:]
    lines: List[str] = []

    for msg in sub:
        role = getattr(msg, "type", "")  # "human", "ai", "system", ...
        if role == "human":
            r = "ì‚¬ìš©ì"
        elif role == "ai":
            r = "ìƒë‹´ê°€"
        else:
            # system / tool ë“±ì€ í”„ë¡¬í”„íŠ¸ì— êµ³ì´ ì•ˆ ë„£ê±°ë‚˜, ì§§ê²Œë§Œ
            r = role or "ê¸°íƒ€"

        content = msg.content
        # contentê°€ list êµ¬ì¡°ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ ì²˜ë¦¬
        if isinstance(content, list):
            text_parts = []
            for item in content:
                if isinstance(item, dict) and item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
            content = "\n".join(text_parts)

        lines.append(f"{r}: {content}")

    return "\n".join(lines)

def _summarize_conversation(state: State, new_ai_message: AIMessage) -> str:
    """
    ì§€ê¸ˆê¹Œì§€ì˜ ìƒë‹´ íë¦„ì„ bullet í¬ì¸íŠ¸ ìš”ì•½ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•œë‹¤.

    - ê¸°ì¡´ state.summary(ìˆìœ¼ë©´)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ â€œì—…ë°ì´íŠ¸â€í•˜ëŠ” í˜•íƒœ
    - ìƒˆë¡œ ì¶”ê°€ëœ ìµœê·¼ ëŒ€í™” + ì´ë²ˆ í„´ AI ë©”ì‹œì§€ë¥¼ ì°¸ê³ í•´ì„œ 3~6ê°œì˜ bulletë¡œ ìš”ì•½
    - state.messagesëŠ” ì ˆëŒ€ ì‚­ì œ/ìˆ˜ì •í•˜ì§€ ì•ŠëŠ”ë‹¤. (trim only in prompt)
    """
    existing_summary = (state.summary or "").strip()

    # ìš”ì•½ì— ì°¸ê³ í•  ìµœê·¼ íˆìŠ¤í† ë¦¬ + ì´ë²ˆ í„´ AI ë©”ì‹œì§€
    history_msgs: List[BaseMessage] = list(state.messages[-6:])
    history_msgs.append(new_ai_message)

    history_lines: List[str] = []
    for msg in history_msgs:
        role = getattr(msg, "type", "")
        if role == "human":
            r = "ì‚¬ìš©ì"
        elif role == "ai":
            r = "ìƒë‹´ê°€"
        else:
            r = role or "ê¸°íƒ€"

        content = msg.content
        if isinstance(content, list):
            text_parts = []
            for item in content:
                if isinstance(item, dict) and item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
            content = "\n".join(text_parts)

        history_lines.append(f"{r}: {content}")

    history_text = "\n".join(history_lines)

    if existing_summary:
        human_prompt = (
            "ë‹¤ìŒì€ ì§€ê¸ˆê¹Œì§€ì˜ ìƒë‹´ ìš”ì•½ì´ì—ìš”:\n"
            f"{existing_summary}\n\n"
            "ê·¸ë¦¬ê³  ì•„ë˜ëŠ” ì´ë²ˆ í„´ í¬í•¨ ìµœê·¼ ëŒ€í™” ì¼ë¶€ì˜ˆìš”:\n"
            f"{history_text}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ëª¨ë‘ ë°˜ì˜í•´ì„œ, ìƒë‹´ ì „ì²´ íë¦„ì„ 3~6ê°œì˜ bullet í¬ì¸íŠ¸ë¡œ í•œêµ­ì–´ë¡œ ì—…ë°ì´íŠ¸í•´ì¤˜.\n"
            "ê° bulletì€ '- 'ë¡œ ì‹œì‘í•˜ëŠ” í•œ ì¤„ ë¬¸ì¥ìœ¼ë¡œ ì¨ì¤˜.\n"
            "- ë‚´ë‹´ìì˜ í•µì‹¬ ê³ ë¯¼\n"
            "- ì´ë²ˆ ì£¼ì°¨ ëª©í‘œì™€ í˜„ì¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©\n"
            "- ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©í•œ CBT ê¸°ë²•/ì „ëµ\n"
            "- ë‚´ë‹´ìê°€ ì–»ì€ ì¸ì‚¬ì´íŠ¸ ë˜ëŠ” í–‰ë™ ê³„íš\n"
            "ì´ ë„¤ ê°€ì§€ ì¶•ì´ ë“œëŸ¬ë‚˜ë„ë¡ ìš”ì•½í•´ì¤˜."
        )
    else:
        human_prompt = (
            "ì•„ë˜ ìƒë‹´ ëŒ€í™”ë¥¼ ë³´ê³ , ìƒë‹´ íë¦„ì˜ í•µì‹¬ì„ 3~6ê°œì˜ bullet í¬ì¸íŠ¸ë¡œ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì¤˜.\n"
            "ê° bulletì€ '- 'ë¡œ ì‹œì‘í•˜ëŠ” í•œ ì¤„ ë¬¸ì¥ìœ¼ë¡œ ì¨ì¤˜.\n"
            "- ë‚´ë‹´ìì˜ í•µì‹¬ ê³ ë¯¼\n"
            "- ì´ë²ˆ ì£¼ì°¨ì—ì„œ ë‹¤ë£¬ ë‚´ìš©\n"
            "- ì‚¬ìš©í•œ CBT ê¸°ë²•/ì „ëµ\n"
            "- ì•ìœ¼ë¡œì˜ í–‰ë™/ê³¼ì œ ë°©í–¥\n"
            "ì´ ë„¤ ê°€ì§€ ì¶•ì´ ë“œëŸ¬ë‚˜ë„ë¡ ì •ë¦¬í•´ì¤˜.\n\n"
            f"[ëŒ€í™”]\n{history_text}"
        )

    messages_for_llm: List[BaseMessage] = [
        SystemMessage(
            content=(
                "ë„ˆëŠ” CBT ê¸°ë°˜ ìƒë‹´ ì„¸ì…˜ì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤.\n"
                "ì‚¬ìš©ìì™€ ìƒë‹´ê°€ì˜ ëŒ€í™”ë¥¼ ë³´ê³ , ìƒë‹´ íë¦„ì„ ì´í•´í•˜ê¸° ì‰¬ìš´ bullet í¬ì¸íŠ¸ë¡œ ì •ë¦¬í•œë‹¤."
            )
        ),
        HumanMessage(content=human_prompt),
    ]

    summary_ai = CHAT_LLM.invoke(messages_for_llm)
    # ì—¬ê¸°ì„œë„ summary_ai.contentê°€ listì¼ ê°€ëŠ¥ì„±ì€ ê±°ì˜ ì—†ì§€ë§Œ, ë°©ì–´ì ìœ¼ë¡œ ì²˜ë¦¬í•´ë„ ë¨
    return summary_ai.content if isinstance(summary_ai.content, str) else str(summary_ai.content)

# === counsel_prepare ===
#helper
def _select_candidate_techniques(state: State) -> List[str]:
    """
    ì´ë²ˆ í„´ì—ì„œ LLMì´ ì„ íƒí•  ìˆ˜ ìˆëŠ” technique í›„ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±.

    ê¸°ë³¸ ì •ì±…:
      - allowed_techniques ì „ì²´ë¥¼ ê¸°ë³¸ í›„ë³´ë¡œ ì‚¬ìš©
      - constraints.blocked_techniques í•­ëª©ì´ ìˆìœ¼ë©´ ì œì™¸
      - technique_historyë¥¼ ì°¸ê³ í•´ ê³¼ë„í•˜ê²Œ ë°˜ë³µëœ ê¸°ë²•ì€ ì„ì‹œ ì œì™¸
    """

    candidates = list(state.allowed_techniques or [])

    # 1) constraints ê¸°ë°˜ í•„í„°ë§
    constraints = state.constraints or {}
    blocked = constraints.get("blocked_techniques", []) or []
    if blocked:
        candidates = [tid for tid in candidates if tid not in blocked]

    # 2) ê°™ì€ ê¸°ë²•ì´ ë„ˆë¬´ ë°˜ë³µëœ ê²½ìš° ì œì™¸ (ì˜ˆ: 3ë²ˆ ì—°ì†)
    technique_history = state.technique_history or []
    if len(technique_history) >= 3:
        last_three = [h.get("technique_id") for h in technique_history[-3:]]
        if len(set(last_three)) == 1:  # ë§ˆì§€ë§‰ 3í„´ ëª¨ë‘ ê°™ì€ ê¸°ë²•ì´ë¼ë©´ overuse
            overused = last_three[0]
            candidates = [tid for tid in candidates if tid != overused]

    return candidates

#helper
def _build_rag_queries(state: State) -> List[str]:
    """
    CBT/CBD RAG ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬ ë¬¸ìì—´ì„ êµ¬ì„±.
    """

    queries: List[str] = []

    # 1) ì„¸ì…˜ ëª©í‘œ ê¸°ë°˜
    if state.session_goal:
        queries.append(f"CBT technique for goal: {state.session_goal}")

    # 2) core_task_tags ê¸°ë°˜
    if state.core_task_tags:
        merged_tags = " / ".join(state.core_task_tags)
        queries.append(f"CBT interventions for: {merged_tags}")

    # 3) ìµœê·¼ ì‚¬ìš©ì ë°œí™” ê¸°ë°˜
    recent_utts: List[str] = []
    for msg in reversed(state.messages):
        if msg.type == "human":
            recent_utts.append(msg.content)
        if len(recent_utts) >= 3:
            break

    if recent_utts:
        combined = " ".join(recent_utts)
        queries.append(f"User situation: {combined[:300]}")

    return queries

#helper
def _retrieve_rag_snippets(queries: List[str], top_k_per_query: int = 4, max_snippets: int = 12) -> List[str]:
    """
    Pinecone ê¸°ë°˜ CBT/CBD RAGë¥¼ ì‹¤ì œë¡œ í˜¸ì¶œí•´ì„œ í…ìŠ¤íŠ¸ ìŠ¤ë‹ˆí«ì„ ê°€ì ¸ì˜¨ë‹¤.

    - search_cbt_corpus(query, top_k)ë¥¼ í˜¸ì¶œí•œë‹¤ê³  ê°€ì •
        - ë°˜í™˜ê°’: LangChain Document ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ìœ ì‚¬í•œ dict ê°ì²´ ë¦¬ìŠ¤íŠ¸
        - ê° ê²°ê³¼ì—ì„œ content/text í•„ë“œë¥¼ êº¼ë‚´ì„œ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“ ë‹¤.
    - ë„¤ í”„ë¡œì íŠ¸ì—ì„œ ì‹¤ì œ RAG í•¨ìˆ˜ ì´ë¦„/ë°˜í™˜ íƒ€ì…ì— ë§ê²Œ
      search_cbt_corpus í˜¸ì¶œ ë¶€ë¶„ê³¼ doc.content ì ‘ê·¼ ë¶€ë¶„ë§Œ ìˆ˜ì •í•˜ë©´ ëœë‹¤.
    """

    snippets: List[str] = []

    for query in queries:
        if not query.strip():
            continue

        try:
            # Pinecone RAG ê²€ìƒ‰ í•¨ìˆ˜
            docs = search_cbt_corpus(query=query, top_k=top_k_per_query)

            for doc in docs:
                # LangChain Document íƒ€ì…ì´ë¼ê³  ê°€ì • (doc.page_content)
                # ë§Œì•½ dictë¡œ ë˜ì–´ ìˆìœ¼ë©´ doc["content"]ì²˜ëŸ¼ ë°”ê¿”ì£¼ë©´ ë¨.
                text = getattr(doc, "page_content", None)
                if text is None and isinstance(doc, dict):
                    text = doc.get("content") or doc.get("text")

                if text:
                    snippets.append(text)

        except Exception as e:
            # RAG ì‹¤íŒ¨í•´ë„ ì „ì²´ í”Œë¡œìš°ê°€ í„°ì§€ì§€ ì•Šë„ë¡ ë°©ì–´
            print(f"[counsel_prepare] RAG ê²€ìƒ‰ ì¤‘ ì—ëŸ¬ ë°œìƒ (query={query!r}): {e}")

        # ì „ì²´ ìŠ¤ë‹ˆí« ê°œìˆ˜ê°€ ë„ˆë¬´ ë§ì•„ì§€ì§€ ì•Šë„ë¡ ì œí•œ
        if len(snippets) >= max_snippets:
            break

    return snippets[:max_snippets]

#node
def counsel_prepare(state: State) -> Dict[str, Any]:
    """
    Dynamic COUNSEL ë£¨í”„ì—ì„œ ë§¤ í„´ ì‹œì‘ ì§ì „ì— ì‹¤í–‰ë˜ëŠ” ì¤€ë¹„ ë…¸ë“œ.
    
    ìˆ˜í–‰ ì‘ì—…:
      - ì´ë²ˆ í„´ì—ì„œ LLMì´ ì„ íƒí•  ìˆ˜ ìˆëŠ” candidate_techniques ê³„ì‚°
      - Pinecone RAGì— ì¿¼ë¦¬ ë‚ ë ¤ CBT/CBD ì´ë¡  ìŠ¤ë‹ˆí«ì„ ê°€ì ¸ì˜¨ë‹¤.
      - ê²°ê³¼ë¥¼ state.candidate_techniques, state.rag_queries, state.rag_snippetsì— ë°˜ì˜í•œë‹¤.
    """

    print("\n=== [DEBUG] counsel_prepare Node Started ===")

    if state.phase != "COUNSEL":
        print(f"[counsel_prepare] phase != 'COUNSEL' (í˜„ì¬: {state.phase!r}) â†’ ì—…ë°ì´íŠ¸ ì—†ìŒ")
        return {}

    updates: Dict[str, Any] = {}

    # 1) í›„ë³´ ê¸°ë²• ë¦¬ìŠ¤íŠ¸
    candidate_techniques = _select_candidate_techniques(state)
    if not candidate_techniques:
        print("[counsel_prepare] ê²½ê³ : candidate_techniquesê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. "
              "allowed_techniques ì „ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        candidate_techniques = list(state.allowed_techniques or [])

    updates["candidate_techniques"] = candidate_techniques

    # 2) RAG ì¿¼ë¦¬ ìƒì„± + Pinecone ê²€ìƒ‰
    rag_queries = _build_rag_queries(state)
    rag_snippets = _retrieve_rag_snippets(rag_queries)

    # updates["rag_queries"] = rag_queries
    updates["rag_snippets"] = rag_snippets

    print("[counsel_prepare] candidate_techniques:", candidate_techniques)
    print("[counsel_prepare] rag_queries:", rag_queries)
    print(f"[counsel_prepare] rag_snippets_count={len(rag_snippets)}")

    return updates


# ======= selector ========
#helper
def _serialize_recent_messages(messages: List[BaseMessage], max_turns: int = 6) -> List[Dict[str, Any]]:
    """
    LLMì— ë„˜ê¸°ê¸° ì¢‹ë„ë¡ ìµœê·¼ ë©”ì‹œì§€ë¥¼ ë‹¨ìˆœ dict í˜•íƒœë¡œ ì§ë ¬í™”.
    - ì—­í• : "human"/"ai"
    - ë‚´ìš©: content í…ìŠ¤íŠ¸

    LangChain ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ë„˜ê²¨ë„ ë˜ì§€ë§Œ,
    í”„ë¡¬í”„íŠ¸ JSONì„ ê¹”ë”í•˜ê²Œ ë§Œë“¤ê³  ì‹¶ì–´ì„œ dictë¡œ ë³€í™˜.
    """
    recent: List[Dict[str, Any]] = []

    for msg in messages[-max_turns:]:
        role = "system"
        if msg.type == "human":
            role = "human"
        elif msg.type == "ai":
            role = "ai"

        recent.append(
            {
                "role": role,
                "content": msg.content,
            }
        )
    return recent

#node
def llm_technique_selector(state: State) -> Dict[str, Any]:
    print("\n=== [DEBUG] select_technique_llm Node Started ===")

    if state.phase != "COUNSEL":
        print(f"[select_technique_llm] phase != 'COUNSEL' (í˜„ì¬: {state.phase!r}) â†’ ì—…ë°ì´íŠ¸ ì—†ìŒ")
        return {}
    
    # intervention.yaml ì¹´íƒˆë¡œê·¸ ë¡œë“œ
    updates: Dict[str, Any] = {}
    catalog = load_techniques_catalog()
    
    # ê¸°ë²• ìœ ì§€(Persistence) ë¡œì§ 
    technique_history = state.technique_history or []
    MIN_PERSISTENCE = 2  # ìµœì†Œ 2í„´ì€ ê°™ì€ ê¸°ë²•ì„ ìœ ì§€ (ì›í•˜ëŠ” ëŒ€ë¡œ ì¡°ì ˆ ê°€ëŠ¥)

    if technique_history:
        last_entry = technique_history[-1]
        last_id = last_entry.get("technique_id")
        
        # ë’¤ì—ì„œë¶€í„° ì„¸ì–´ì„œ ì—°ì†ìœ¼ë¡œ ëª‡ ë²ˆ ì¼ëŠ”ì§€ ê³„ì‚°
        consecutive_count = 0
        for entry in reversed(technique_history):
            if entry.get("technique_id") == last_id:
                consecutive_count += 1
            else:
                break
        
        # ì•„ì§ ìµœì†Œ ìœ ì§€ í„´ìˆ˜ë¥¼ ì±„ìš°ì§€ ëª»í–ˆë‹¤ë©´ -> LLM í˜¸ì¶œ ì—†ì´ ê¸°ì¡´ ê¸°ë²• ìœ ì§€
        if last_id in catalog and consecutive_count < MIN_PERSISTENCE:
            print(f"[select_technique_llm] ğŸ”’ ê¸°ë²• ìœ ì§€ ëª¨ë“œ: '{last_id}' (ì—°ì† {consecutive_count}íšŒ ì‚¬ìš© ì¤‘)")
            
            # ë©”íƒ€ë°ì´í„° ë‹¤ì‹œ ë¡œë“œ (í˜¹ì‹œ Stateì—ì„œ ìœ ì‹¤ëì„ ê²½ìš° ëŒ€ë¹„)
            meta = catalog[last_id]
            
            # ê¸°ì¡´ micro_goalì„ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê±°ë‚˜, í•„ìš”í•˜ë©´ ë¹ˆì¹¸ìœ¼ë¡œ ë‘ì–´ Applierê°€ íë¦„ì„ ì‡ê²Œ í•¨
            # ì—¬ê¸°ì„œëŠ” ì´ì „ micro_goalì„ ê·¸ëŒ€ë¡œ ê³„ìŠ¹
            last_micro_goal = last_entry.get("micro_goal", "")

            return {
                "selected_technique_id": last_id,
                "selected_technique_meta": {"id": last_id, **meta},
                "micro_goal": last_micro_goal 
            }
    # ------------------------------------------------------------------

    # ìƒˆ ê¸°ë²• ì„ ì •
    # candidate_techniques í™•ë³´ (ì—†ìœ¼ë©´ allowed_techniquesë¡œ fallback)
    candidate_ids = state.candidate_techniques or state.allowed_techniques or []
    if not candidate_ids:
        print("[select_technique_llm] ê²½ê³ : candidate_techniquesì™€ allowed_techniquesê°€ ëª¨ë‘ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return {}

    
    candidate_defs: List[Dict[str, Any]] = []
    for tid in candidate_ids:
        meta = catalog.get(tid)
        if meta is None:
            print(f"[select_technique_llm] ê²½ê³ : intervention catalogì— ì—†ëŠ” technique_id: {tid!r}")
            continue
        candidate_defs.append(
            {
                "id": tid,
                **meta,
            }
        )

    if not candidate_defs:
        print("[select_technique_llm] ê²½ê³ : catalogì—ì„œ ìœ íš¨í•œ candidate_defsë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return {}

    # 3) ìµœê·¼ ë©”ì‹œì§€ ì§ë ¬í™”
    recent_messages = _serialize_recent_messages(state.messages)
    rag_snippets_preview = (state.rag_snippets or [])[:3]
    
    # 4) ì—¬ê¸°ì„œ prompt ë©”ì‹œì§€ ì§ì ‘ êµ¬ì„±
    system_content = (
        PERSONA
        + "\n\n"
        "ë„ˆëŠ” CBT ê¸°ë°˜ ì¶©ë™/ìŠµê´€ì  ì†Œë¹„ êµì •ì„ ë•ëŠ” 'ê¸°ë²• ì½”ë””ë„¤ì´í„°' ìƒë‹´ê°€ë‹¤.\n"
        "ë„¤ ì„ë¬´ëŠ” ì´ë²ˆ í„´ì— ì‚¬ìš©í•  **ë”± í•˜ë‚˜ì˜ CBT ê¸°ë²•(technique_id)** ì„ ê³ ë¥´ê³ ,\n"
        "ê·¸ ê¸°ë²•ìœ¼ë¡œ ì´ë²ˆ í„´ì— ë‹¬ì„±í•  micro-goal ì„ ì •ì˜í•˜ëŠ” ê²ƒì´ë‹¤.\n\n"

        "ê° í›„ë³´ ê¸°ë²•(candidate_techniques)ì€ techniques.yamlì—ì„œ ì˜¨ ë©”íƒ€ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆë‹¤.\n"
        "ê° ê¸°ë²•ì—ëŠ” ëŒ€ëµ ë‹¤ìŒê³¼ ê°™ì€ í•„ë“œê°€ ìˆë‹¤:\n"
        "- id: ë‚´ë¶€ ì‹ë³„ì (ì˜ˆ: identifying_automatic_thoughts)\n"
        "- level: 'intervention' ë˜ëŠ” 'technique'\n"
        "- typical_targets: ì´ ê¸°ë²•ì´ ì§ì ‘ì ìœ¼ë¡œ ë‹¤ë£¨ëŠ” ë¬¸ì œ/ìƒíƒœ íƒœê·¸ë“¤\n"
        "- good_for_focus: ì„¸ì…˜ì˜ ì´ˆì (agenda, session_goal, core_task_tags)ì— ì˜ ë§ëŠ” ì˜ì—­ íƒœê·¸ë“¤\n"
        "- rag_tags: ì´ë¡  ìŠ¤ë‹ˆí« ê²€ìƒ‰ì— ì‚¬ìš©í•˜ëŠ” íƒœê·¸ë“¤\n\n"

        "ê¸°ë²• ì„ íƒ ì‹œ ë‹¤ìŒ ì›ì¹™ì„ ë”°ë¥´ë¼:\n"
        "1) **ì„¸ì…˜ ì´ˆì ê³¼ì˜ ì •í•©ì„± (good_for_focus ê¸°ì¤€)**\n"
        "   - ì•„ë˜ì— ì£¼ì–´ì§„ session_goal, agenda, core_task_tags ë¥¼ í•˜ë‚˜ì˜ 'ì„¸ì…˜ ì´ˆì  íƒœê·¸ ì§‘í•©'ìœ¼ë¡œ ë³´ê³ ,\n"
        "     ê° ê¸°ë²•ì˜ good_for_focus ì™€ ì–¼ë§ˆë‚˜ ë§ì´ ê²¹ì¹˜ëŠ”ì§€ í‰ê°€í•˜ë¼.\n"
        "   - ì„¸ì…˜ì´ ì§‘ì¤‘í•˜ê³ ì í•˜ëŠ” í…Œë§ˆì™€ ì˜ ë§ëŠ” ê¸°ë²•ì— ê°€ì¤‘ì¹˜ë¥¼ ë‘”ë‹¤.\n\n"
        "2) **ì‚¬ìš©ì í˜„ì¬ ìƒíƒœì™€ì˜ ì •í•©ì„± (typical_targets ê¸°ì¤€)**\n"
        "   - recent_messages, session_progress, rag_snippets ì— ë‚˜íƒ€ë‚œ ì‚¬ìš©ìì˜ í˜„ì¬ ê³ ë¯¼, ê°ì •, í–‰ë™ íŒ¨í„´ì„ ì½ê³ ,\n"
        "     ê·¸ê²ƒì„ íƒœê·¸í™”í–ˆë‹¤ê³  ê°€ì •í•˜ê³  ê° ê¸°ë²•ì˜ typical_targets ì™€ì˜ ì¼ì¹˜ ì •ë„ë¥¼ í‰ê°€í•˜ë¼.\n"
        "   - ì‚¬ìš©ìê°€ \"ì§€ê¸ˆ ë‹¹ì¥\" ê²ªê³  ìˆëŠ” ë¬¸ì œë¥¼ ì§ì ‘ì ìœ¼ë¡œ ë‹¤ë£° ìˆ˜ ìˆëŠ” ê¸°ë²•ì„ ìµœìš°ì„ ìœ¼ë¡œ ê³ ë ¤í•œë‹¤.\n\n"
        "3) **ìš°ì„ ìˆœìœ„ ê·œì¹™**\n"
        "   - 1ì°¨ ê¸°ì¤€: typical_targets ì™€ì˜ ì¼ì¹˜ë„ (ì‚¬ìš©ì ìƒíƒœì™€ ì–¼ë§ˆë‚˜ ì§ì ‘ì ìœ¼ë¡œ ë§ë‹¿ëŠ”ê°€)\n"
        "   - 2ì°¨ ê¸°ì¤€: good_for_focus ì™€ì˜ ì¼ì¹˜ë„ (ì´ë²ˆ ì„¸ì…˜ì˜ agenda / session_goal / core_task_tags ì™€ì˜ ì •í•©ì„±)\n"
        "   - 3ì°¨ ê¸°ì¤€: technique_history ë¥¼ ì°¸ê³ í•˜ì—¬, ê°™ì€ ê¸°ë²•ì´ ê³¼ë„í•˜ê²Œ ë°˜ë³µë˜ì§€ ì•Šë„ë¡ ì¡°ì •í•˜ë¼.\n"
        "     (ë‹¨, íŠ¹ì • ê¸°ë²•ì„ ë°˜ë³µ í›ˆìŠµí•˜ëŠ” ê²ƒì´ core_task ë‹¬ì„±ì— í•„ìˆ˜ì ì´ë¼ë©´ ë°˜ë³µ ì„ íƒë„ í—ˆìš©í•œë‹¤.)\n"
        "   - 4ì°¨ ê¸°ì¤€: level ê³¼ ë‚œì´ë„. ì´ˆê¸°/ë¶ˆì•ˆì • ìƒíƒœì—ì„œëŠ” ë„ˆë¬´ ë¬´ê±°ìš´ schema/core belief ì‘ì—…ë³´ë‹¤\n"
        "     ê°ì • ë¼ë²¨ë§, ìë™ì‚¬ê³  ìœ ë„, ì¦ê±° íƒìƒ‰ ë“± ë¹„êµì  ë¶€ë‹´ì´ ëœí•œ ê¸°ë²•ì„ ìš°ì„  ì‚¬ìš©í•˜ë¼.\n\n"
        "4) **ì„ íƒ ê²°ê³¼**\n"
        "   - TechniqueSelection.technique_id ì—ëŠ” ë°˜ë“œì‹œ ìœ„ í›„ë³´ ëª©ë¡ ì¤‘ í•˜ë‚˜ì˜ id ë§Œ ë„£ì–´ë¼.\n"
        "   - micro_goal ì€, ì„ íƒí•œ ê¸°ë²•ì„ ì´ìš©í•´ ì´ë²ˆ í„´ì— ì‹¤ì œë¡œ ë¬´ì—‡ì„ í•´ë³¼ì§€\n"
        "     'í•œ ë²ˆì˜ í„´ì—ì„œ ë‹¬ì„± ê°€ëŠ¥í•œ í¬ê¸°'ë¡œ êµ¬ì²´ì  í–‰ë™/ì‚¬ê³  ì‘ì—… ë‹¨ìœ„ë¡œ ì ì–´ë¼.\n"
        "   - reason ì—ëŠ” ìœ„ ê¸°ì¤€(typical_targets, good_for_focus, technique_history ë“±)ì„ í† ëŒ€ë¡œ\n"
        "     ì™œ ì´ ê¸°ë²•ì´ ì§€ê¸ˆ í„´ì— ê°€ì¥ ì í•©í•œì§€ ê°„ë‹¨íˆ ì„¤ëª…í•˜ë¼.\n\n"
        "ì‘ë‹µì€ ë°˜ë“œì‹œ TechniqueSelection ìŠ¤í‚¤ë§ˆì— ë§ëŠ” JSON í˜•ì‹ì´ì–´ì•¼ í•œë‹¤.\n"
        "- technique_id: ì„ íƒí•œ CBT ê¸°ë²•ì˜ ID (ë¬¸ìì—´, í›„ë³´ ëª©ë¡ ì¤‘ í•˜ë‚˜)\n"
        "- micro_goal: ì´ë²ˆ í„´ì—ì„œ ë‹¬ì„±í•  êµ¬ì²´ì ì¸ ëª©í‘œ (ë¬¸ìì—´)\n"
        "- reason: ì´ ì„ íƒì´ ì ì ˆí•œ ì´ìœ  (ë¬¸ìì—´)\n\n"

        f"- ì„¸ì…˜ ëª©í‘œ(session_goal): {state.session_goal}\n"
        f"- ì„¸ì…˜ agenda: {getattr(state, 'agenda', None)}\n"
        f"- í•µì‹¬ ì‘ì—… íƒœê·¸(core_task_tags): {state.core_task_tags}\n"
        f"- ì„¸ì…˜ ì§„í–‰ë„(session_progress): {state.session_progress}\n"
        f"- ê¸°ë²• ì‚¬ìš© íˆìŠ¤í† ë¦¬(technique_history): {state.technique_history}\n"
        f"- ì„¸ì…˜ ì œì•½(constraints): {state.constraints}\n"
        f"- RAG ì´ë¡  ìŠ¤ë‹ˆí« ì¼ë¶€(rag_snippets_preview): {rag_snippets_preview}\n"
        f"- í›„ë³´ ê¸°ë²• ëª©ë¡(candidate_techniques with meta): {candidate_defs}\n"
    )
    human_content = (
        "ì•„ë˜ëŠ” ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ì•¼.\n"
        "ì´ íˆìŠ¤í† ë¦¬ì™€ ì„¸ì…˜ ì •ë³´, candidate_techniques ì˜ typical_targets / good_for_focus ë¥¼ ì°¸ê³ í•´ì„œ,\n"
        "ì§€ê¸ˆ ì‚¬ìš©ìì—ê²Œ **ë„ˆë¬´ ë¬´ê²ì§€ ì•Šì§€ë§Œ ë¶„ëª…í•œ í•œ ê±¸ìŒ**ì„ ë§Œë“¤ ìˆ˜ ìˆëŠ” CBT ê¸°ë²•ì„ í•˜ë‚˜ë§Œ ê³¨ë¼.\n\n"
        "1) ì‚¬ìš©ìê°€ í˜„ì¬ ê²ªëŠ” í•µì‹¬ ë¬¸ì œ/ê°ì •/ì‚¬ê³  íŒ¨í„´ê³¼ ì˜ ë§ëŠ”ì§€(typical_targets ê¸°ì¤€)ë¥¼ ë¨¼ì € ë³¸ ë‹¤ìŒ,\n"
        "2) ì´ë²ˆ ì„¸ì…˜ì˜ agenda, session_goal, core_task_tags ì™€ë„ ì˜ ë§ëŠ”ì§€(good_for_focus ê¸°ì¤€)ë¥¼ ê³ ë ¤í•´ì„œ\n"
        "   ìµœì¢…ì ìœ¼ë¡œ ê°€ì¥ ì í•©í•œ ê¸°ë²•ì„ ì„ íƒí•´.\n\n"
        "ê·¸ë¦¬ê³  ê·¸ ê¸°ë²•ìœ¼ë¡œ ì´ë²ˆ í„´ì—ì„œ í•´ë³¼ ìˆ˜ ìˆëŠ” í•œ í„´ì§œë¦¬ micro-goal ì„ ì •ë¦¬í•´ì¤˜.\n\n"
        f"ìµœê·¼ ëŒ€í™” ìš”ì•½(recent_messages): {recent_messages}\n\n"
        "TechniqueSelection ìŠ¤í‚¤ë§ˆì— ë§ëŠ” JSONë§Œ ë°˜í™˜í•´."
    )


    messages = [
        SystemMessage(content=system_content),
        HumanMessage(content=human_content),
    ]

    print("[select_technique_llm] LLM ë©”ì‹œì§€ ì¤€ë¹„ ì™„ë£Œ. candidate ê°œìˆ˜:", len(candidate_defs))

    # 5) LLM í˜¸ì¶œ (ì´ì œ messagesë¥¼ ë°”ë¡œ ë„£ìŒ)
    result = TECHNIQUE_SELECTOR.invoke(messages)

    # 6) ê²°ê³¼ í•´ì„ ë° ë°©ì–´ì  ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ì¬ì‚¬ìš©)
    technique_id = result.technique_id
    micro_goal = result.micro_goal
    reason = result.reason

    if not technique_id:
        print("[select_technique_llm] ê²½ê³ : LLMì´ technique_idë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return {}

    if technique_id not in catalog:
        print(f"[select_technique_llm] ê²½ê³ : LLMì´ ê³ ë¥¸ technique_id={technique_id!r}ê°€ catalogì— ì—†ìŠµë‹ˆë‹¤.")
        fallback_id = candidate_ids[0]
        technique_id = fallback_id
        reason = (reason or "") + "\n[FALLBACK] catalogì— ì—†ëŠ” ê¸°ë²•ì´ë¼ ì²« í›„ë³´ë¡œ ëŒ€ì²´."

    technique_meta = {
        "id": technique_id,
        **catalog[technique_id],
        "llm_reason": reason,
    }

    updates["selected_technique_id"] = technique_id
    updates["selected_technique_meta"] = technique_meta
    updates["micro_goal"] = micro_goal or ""

    print(f"[select_technique_llm] ì„ íƒëœ ê¸°ë²•: {technique_id}")
    print(f"[select_technique_llm] micro_goal: {updates['micro_goal']!r}")

    return updates


# ===== applier ======
#node
def llm_technique_applier(state: State) -> Dict[str, Any]:
    print("\n=== [DEBUG] llm_technique_applier Node Started ===")

    if state.phase != "COUNSEL":
        print(f"[applier] phase != 'COUNSEL' (í˜„ì¬: {state.phase!r}) â†’ ìŠ¤í‚µ")
        return {}

    if not state.selected_technique_id:
        print("[applier] selected_technique_idê°€ ì—†ìŠµë‹ˆë‹¤. â†’ ìŠ¤í‚µ")
        return {}

    # 1) ìµœê·¼ ë©”ì‹œì§€ ì§ë ¬í™”
    recent_messages = _serialize_recent_messages(state.messages)

    # 2) System + Human ë©”ì‹œì§€ êµ¬ì„±
    system_content = (
        PERSONA
        + "\n\n"
        "ë„ˆëŠ” CBT ê¸°ë°˜ ì¶©ë™/ìŠµê´€ì  ì†Œë¹„ êµì •ì„ ë•ëŠ” ì „ë¬¸ ìƒë‹´ê°€ë‹¤.\n"
        "ì•„ë˜ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬, ì´ë²ˆ í„´ì—ì„œ ì„ íƒëœ CBT ê¸°ë²•ì„ í™œìš©í•´ "
        "ì‚¬ìš©ìê°€ ì„¸ì…˜ ëª©í‘œì— í•œ ê±¸ìŒ ë” ë‹¤ê°€ê°€ë„ë¡ ë•ëŠ” ìƒë‹´ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ë¼.\n\n"
        "ì‘ë‹µì€ ë°˜ë“œì‹œ CounselorTurn ìŠ¤í‚¤ë§ˆì— ë§ëŠ” JSONìœ¼ë¡œ ë°˜í™˜í•´ì•¼ í•œë‹¤.\n\n"
        f"- ì„¸ì…˜ ëª©í‘œ(session_goal): {state.session_goal}\n"
        f"- í•µì‹¬ ì‘ì—… íƒœê·¸(core_task_tags): {state.core_task_tags}\n"
        f"- ì„ íƒëœ ê¸°ë²•(selected_technique): {state.selected_technique_id}\n"
        f"- ì´ ê¸°ë²•ì˜ ì„¤ëª…(selected_technique_meta): {state.selected_technique_meta}\n"
        f"- RAG ì´ë¡  ìŠ¤ë‹ˆí«(rag_snippets): {state.rag_snippets}\n"
        f"- ì„¸ì…˜ ì§„í–‰ë„(session_progress): {state.session_progress}\n"
        f"- ì´ë²ˆ í„´ì˜ micro_goal: {state.micro_goal}\n"
        f"- ì§€ê¸ˆê¹Œì§€ì˜ ìƒë‹´ ìš”ì•½(summary): {state.summary}\n"
        f"- ìµœê·¼ ëŒ€í™” ìš”ì•½(recent_messages):\n{recent_messages}\n"
    )

    last_user_input = ""
    if state.messages:
        last_msg = state.messages[-1]
        if getattr(last_msg, "type", "") == "human":
            content = last_msg.content
            if isinstance(content, list):
                parts = []
                for item in content:
                    if isinstance(item, dict) and item.get("type") == "text":
                        parts.append(item.get("text", ""))
                last_user_input = "\n".join(parts)
            else:
                last_user_input = content

    human_content = (
        "ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ, ì´ë²ˆ í„´ì—ì„œ ì‚¬ìš©í•  CBT ê¸°ë²•ì„ ì‹¤ì œë¡œ ì ìš©í•˜ëŠ” ìƒë‹´ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì¤˜.\n"
        "ë©”ì‹œì§€ëŠ” ì‚¬ìš©ìê°€ ë°”ë¡œ ì½ì„ ìˆ˜ ìˆëŠ” í•œêµ­ì–´ ìƒë‹´ ë©˜íŠ¸ í˜•íƒœì—¬ì•¼ í•˜ê³ , "
        "CounselorTurn ìŠ¤í‚¤ë§ˆì— ë§ëŠ” JSONìœ¼ë¡œ ë°˜í™˜í•´ì•¼ í•´.\n\n"
        f"ì‚¬ìš©ìì˜ ë§ˆì§€ë§‰ ë°œí™”: {last_user_input}"
    )

    messages = [
        SystemMessage(content=system_content),
        HumanMessage(content=human_content),
    ]

    # 3) LLM í˜¸ì¶œ (CounselorTurn êµ¬ì¡°)
    structured_output = LLM_CHAIN.invoke(messages)

    response_text = structured_output.response_text
    reasoning = structured_output.reasoning or ""
    progress_delta = structured_output.progress_delta or {}
    criteria_evals = structured_output.criteria_evaluations or []
    llm_suggest = structured_output.suggest_end_session
    llm_session_goals_met = structured_output.session_goals_met

    # 4) technique_history ì—…ë°ì´íŠ¸
    technique_history = list(state.technique_history or [])
    technique_history.append(
        {
            "technique_id": state.selected_technique_id,
            "micro_goal": state.micro_goal,
            "reasoning": reasoning,
        }
    )

    # 5) session_progress ì—…ë°ì´íŠ¸
    new_session_progress: Dict[str, Any] = dict(state.session_progress or {})
    # progress_delta ë°˜ì˜
    if progress_delta:
        # 1. Pydantic ëª¨ë¸ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (exclude_unset=True ê¶Œì¥)
        # exclude_unset=True: LLMì´ ì‹¤ì œë¡œ ê°’ì„ ì±„ìš´ í•„ë“œë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤. (Noneì¸ í•„ë“œ ì œì™¸)
        delta_dict = progress_delta.model_dump(exclude_unset=True)
        
        # 2. ë”•ì…”ë„ˆë¦¬ ìˆœíšŒí•˜ë©° ì—…ë°ì´íŠ¸
        for key, value in delta_dict.items():
            if value is not None:  # í•œ ë²ˆ ë” ì•ˆì „í•˜ê²Œ ì²´í¬
                new_session_progress[key] = value

    # turn_count += 1
    existing_turn_count = new_session_progress.get("turn_count", 0)
    try:
        existing_turn_count = int(existing_turn_count)
    except (TypeError, ValueError):
        existing_turn_count = 0
    new_session_progress["turn_count"] = existing_turn_count + 1

    # 6) criteria_status ì—…ë°ì´íŠ¸
    criteria_status: Dict[str, bool] = dict(state.criteria_status or {})
    for ev in criteria_evals:
        # CounselorTurn.CriterionEvaluation
        criteria_status[ev.criterion_id] = ev.met
        
    # 7) ì´ë²ˆ í„´ AI ë©”ì‹œì§€ ê°ì²´ ìƒì„±
    ai_message = AIMessage(content=response_text)    

    print("ğŸ¤– [applier] LLM Response:")
    print(f"   - Technique: {state.selected_technique_id}")
    print(f"   - Micro goal: {state.micro_goal}")
    print(f"   - Reasoning: {reasoning}")
    print(f"   - Progress delta: {progress_delta}")
    print(f"   - Criteria evals: {[ (e.criterion_id, e.met) for e in criteria_evals ]}")
    print(f"   - turn_count -> {new_session_progress['turn_count']}")
    print(f"   - suggest_end_session: {llm_suggest}, session_goals_met: {llm_session_goals_met}")
    print(f"   - Assistant: {response_text[:120]}...")
    
    return {
        "messages": [AIMessage(content=response_text)],
        "llm_output": response_text,
        "technique_history": technique_history,
        "session_progress": new_session_progress,
        "criteria_status": criteria_status,
        "llm_suggest_end_session": llm_suggest,
    }
    
# ===== summarizer ======
def summarize_and_filter_message(state: State) -> Dict[str, Any]:
    """
    [ë…¸ë“œ] ëŒ€í™” ë‚´ì—­ì´ ê¸¸ì–´ì§€ë©´ ìš”ì•½í•˜ê³  Stateì—ì„œ ë©”ì‹œì§€ë¥¼ ì‚­ì œí•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ë¥¼ ê´€ë¦¬í•¨.
    """
    print("\n=== [DEBUG] SummarizeAndPrune Node Started ===")
    
    # 1. ì„¤ì •: ìœ ì§€í•  ë©”ì‹œì§€ ê°œìˆ˜ (ìµœê·¼ ëŒ€í™” Nê°œëŠ” ì‚´ë ¤ë‘ )
    KEEP_LAST_N = 6 
    # ì„¤ì •: ìš”ì•½ì„ ì‹¤í–‰í•  ì„ê³„ê°’ (ë©”ì‹œì§€ê°€ ì´ë³´ë‹¤ ë§ìœ¼ë©´ ì •ë¦¬ ì‹œì‘)
    THRESHOLD = 10

    messages = state.messages
    
    # ë©”ì‹œì§€ê°€ ë³„ë¡œ ì—†ìœ¼ë©´ ì•„ë¬´ê²ƒë„ ì•ˆ í•˜ê³  íŒ¨ìŠ¤
    if len(messages) <= THRESHOLD:
        print("[Prune] ë©”ì‹œì§€ ê°œìˆ˜ê°€ ì ì–´ì„œ ì •ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return {}

    # 2. ìš”ì•½í•  ëŒ€ìƒê³¼ ë‚¨ê¸¸ ëŒ€ìƒ ë¶„ë¦¬
    # messages[:-KEEP_LAST_N] -> ìš”ì•½í•˜ê³  ì§€ìš¸ ì• ë“¤ (ì˜¤ë˜ëœ ê²ƒ)
    to_summarize = messages[:-KEEP_LAST_N]
    
    # 3. ìš”ì•½ ìˆ˜í–‰ (LLM í˜¸ì¶œ)
    # ìš”ì•½í•  ë©”ì‹œì§€ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    conversation_text = ""
    for msg in to_summarize:
        role = "User" if msg.type == "human" else "Assistant"
        conversation_text += f"{role}: {msg.content}\n"

    current_summary = state.summary or "ì—†ìŒ"

    prompt = (
        f"ê¸°ì¡´ ìš”ì•½:\n{current_summary}\n\n"
        f"ì‚­ì œë  ì˜¤ë˜ëœ ëŒ€í™”:\n{conversation_text}\n\n"
        "ìœ„ 'ì˜¤ë˜ëœ ëŒ€í™”'ì˜ í•µì‹¬ ë‚´ìš©(ì‚¬ê±´, ê°ì •, ì£¼ìš” ë°œì–¸)ì„ 'ê¸°ì¡´ ìš”ì•½'ì— í†µí•©í•´ì„œ "
        "ìƒˆë¡œìš´ ìš”ì•½ë¬¸ì„ ì‘ì„±í•´ì¤˜. "
        "ë¶„ì„ë³´ë‹¤ëŠ” íŒ©íŠ¸ ìœ„ì£¼ë¡œ ê°„ê²°í•˜ê²Œ ê¸°ë¡í•´."
    )
    
    # ìš”ì•½ LLM í˜¸ì¶œ (CHAT_LLM ì‚¬ìš©)
    response = CHAT_LLM.invoke([
        SystemMessage(content="ë„ˆëŠ” ìƒë‹´ ê¸°ë¡ ìš”ì•½ê°€ë‹¤."),
        HumanMessage(content=prompt)
    ])
    new_summary = response.content

    # 4. ë©”ì‹œì§€ ì‚­ì œ ì˜¤í¼ë ˆì´ì…˜ ìƒì„±
    # LangGraphì—ì„œ RemoveMessage(id=...)ë¥¼ ë¦¬í„´í•˜ë©´ Stateì—ì„œ ì‚¬ë¼ì§
    delete_ops = []
    for msg in to_summarize:
        if msg.id:
            delete_ops.append(RemoveMessage(id=msg.id))

    print(f"ğŸ§¹ [Prune] ë©”ì‹œì§€ {len(to_summarize)}ê°œ ì‚­ì œ & ìš”ì•½ ê°±ì‹  ì™„ë£Œ.")

    # 5. State ì—…ë°ì´íŠ¸ ë°˜í™˜
    return {
        "summary": new_summary,   # ìš”ì•½ ê°±ì‹ 
        "messages": delete_ops    # ì˜¤ë˜ëœ ë©”ì‹œì§€ ì‚­ì œ ëª…ë ¹
    }