# coach_agent/graph/counsel_nodes.py

from __future__ import annotations
from typing import Dict, Any, List
from langchain_core.messages import BaseMessage, AIMessage, SystemMessage, HumanMessage
from coach_agent.graph.state import State
from coach_agent.prompts.identity import COMMON_IDENTITY
from coach_agent.services.llm import TECHNIQUE_SELECTOR, LLM_CHAIN, CHAT_LLM
from coach_agent.utils.protocol_loader import load_techniques_catalog
from coach_agent.rag.search import search_cbt_corpus  # â† ë„¤ RAG ëª¨ë“ˆì— ë§žê²Œ import ìˆ˜ì •

# === summarizing helpers ===
def _serialize_recent_messages(
    messages: List[BaseMessage],
    max_turns: int = 6,
) -> str:
    """
    í”„ë¡¬í”„íŠ¸ì— ë„£ê¸° ìœ„í•œ 'ìµœê·¼ ëŒ€í™” ìš”ì•½ í…ìŠ¤íŠ¸' ìƒì„±.
    - ì „ì²´ ížˆìŠ¤í† ë¦¬ë¥¼ ê±´ë“œë¦¬ì§€ ì•Šê³ , ë§ˆì§€ë§‰ max_turns ê°œë§Œ í…ìŠ¤íŠ¸ë¡œ ì§ë ¬í™”
    - Human/AI ì¤‘ì‹¬ìœ¼ë¡œ role ë¼ë²¨ì„ ë¶™ì—¬ì¤€ë‹¤.
    """
    if not messages:
        return ""

    sub = messages[-max_turns:]
    lines: List[str] = []

    for msg in sub:
        role = getattr(msg, "type", "")  # "human", "ai", "system", ...
        if role == "human":
            r = "ì‚¬ìš©ìž"
        elif role == "ai":
            r = "ìƒë‹´ê°€"
        else:
            # system / tool ë“±ì€ í”„ë¡¬í”„íŠ¸ì— êµ³ì´ ì•ˆ ë„£ê±°ë‚˜, ì§§ê²Œë§Œ
            r = role or "ê¸°íƒ€"

        content = msg.content
        # contentê°€ list êµ¬ì¡°ì¼ ìˆ˜ë„ ìžˆìœ¼ë¯€ë¡œ ì²˜ë¦¬
        if isinstance(content, list):
            text_parts = []
            for item in content:
                if isinstance(item, dict) and item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
            content = "\n".join(text_parts)

        lines.append(f"{r}: {content}")

    return "\n".join(lines)

def _summarize_conversation(state: State, new_ai_message: AIMessage) -> str:
    """
    ì§€ê¸ˆê¹Œì§€ì˜ ìƒë‹´ íë¦„ì„ bullet í¬ì¸íŠ¸ ìš”ì•½ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•œë‹¤.

    - ê¸°ì¡´ state.summary(ìžˆìœ¼ë©´)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ â€œì—…ë°ì´íŠ¸â€í•˜ëŠ” í˜•íƒœ
    - ìƒˆë¡œ ì¶”ê°€ëœ ìµœê·¼ ëŒ€í™” + ì´ë²ˆ í„´ AI ë©”ì‹œì§€ë¥¼ ì°¸ê³ í•´ì„œ 3~6ê°œì˜ bulletë¡œ ìš”ì•½
    - state.messagesëŠ” ì ˆëŒ€ ì‚­ì œ/ìˆ˜ì •í•˜ì§€ ì•ŠëŠ”ë‹¤. (trim only in prompt)
    """
    existing_summary = (state.summary or "").strip()

    # ìš”ì•½ì— ì°¸ê³ í•  ìµœê·¼ ížˆìŠ¤í† ë¦¬ + ì´ë²ˆ í„´ AI ë©”ì‹œì§€
    history_msgs: List[BaseMessage] = list(state.messages[-6:])
    history_msgs.append(new_ai_message)

    history_lines: List[str] = []
    for msg in history_msgs:
        role = getattr(msg, "type", "")
        if role == "human":
            r = "ì‚¬ìš©ìž"
        elif role == "ai":
            r = "ìƒë‹´ê°€"
        else:
            r = role or "ê¸°íƒ€"

        content = msg.content
        if isinstance(content, list):
            text_parts = []
            for item in content:
                if isinstance(item, dict) and item.get("type") == "text":
                    text_parts.append(item.get("text", ""))
            content = "\n".join(text_parts)

        history_lines.append(f"{r}: {content}")

    history_text = "\n".join(history_lines)

    if existing_summary:
        human_prompt = (
            "ë‹¤ìŒì€ ì§€ê¸ˆê¹Œì§€ì˜ ìƒë‹´ ìš”ì•½ì´ì—ìš”:\n"
            f"{existing_summary}\n\n"
            "ê·¸ë¦¬ê³  ì•„ëž˜ëŠ” ì´ë²ˆ í„´ í¬í•¨ ìµœê·¼ ëŒ€í™” ì¼ë¶€ì˜ˆìš”:\n"
            f"{history_text}\n\n"
            "ìœ„ ì •ë³´ë¥¼ ëª¨ë‘ ë°˜ì˜í•´ì„œ, ìƒë‹´ ì „ì²´ íë¦„ì„ 3~6ê°œì˜ bullet í¬ì¸íŠ¸ë¡œ í•œêµ­ì–´ë¡œ ì—…ë°ì´íŠ¸í•´ì¤˜.\n"
            "ê° bulletì€ '- 'ë¡œ ì‹œìž‘í•˜ëŠ” í•œ ì¤„ ë¬¸ìž¥ìœ¼ë¡œ ì¨ì¤˜.\n"
            "- ë‚´ë‹´ìžì˜ í•µì‹¬ ê³ ë¯¼\n"
            "- ì´ë²ˆ ì£¼ì°¨ ëª©í‘œì™€ í˜„ìž¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©\n"
            "- ì§€ê¸ˆê¹Œì§€ ì‚¬ìš©í•œ CBT ê¸°ë²•/ì „ëžµ\n"
            "- ë‚´ë‹´ìžê°€ ì–»ì€ ì¸ì‚¬ì´íŠ¸ ë˜ëŠ” í–‰ë™ ê³„íš\n"
            "ì´ ë„¤ ê°€ì§€ ì¶•ì´ ë“œëŸ¬ë‚˜ë„ë¡ ìš”ì•½í•´ì¤˜."
        )
    else:
        human_prompt = (
            "ì•„ëž˜ ìƒë‹´ ëŒ€í™”ë¥¼ ë³´ê³ , ìƒë‹´ íë¦„ì˜ í•µì‹¬ì„ 3~6ê°œì˜ bullet í¬ì¸íŠ¸ë¡œ í•œêµ­ì–´ë¡œ ìš”ì•½í•´ì¤˜.\n"
            "ê° bulletì€ '- 'ë¡œ ì‹œìž‘í•˜ëŠ” í•œ ì¤„ ë¬¸ìž¥ìœ¼ë¡œ ì¨ì¤˜.\n"
            "- ë‚´ë‹´ìžì˜ í•µì‹¬ ê³ ë¯¼\n"
            "- ì´ë²ˆ ì£¼ì°¨ì—ì„œ ë‹¤ë£¬ ë‚´ìš©\n"
            "- ì‚¬ìš©í•œ CBT ê¸°ë²•/ì „ëžµ\n"
            "- ì•žìœ¼ë¡œì˜ í–‰ë™/ê³¼ì œ ë°©í–¥\n"
            "ì´ ë„¤ ê°€ì§€ ì¶•ì´ ë“œëŸ¬ë‚˜ë„ë¡ ì •ë¦¬í•´ì¤˜.\n\n"
            f"[ëŒ€í™”]\n{history_text}"
        )

    messages_for_llm: List[BaseMessage] = [
        SystemMessage(
            content=(
                "ë„ˆëŠ” CBT ê¸°ë°˜ ìƒë‹´ ì„¸ì…˜ì˜ ë‚´ìš©ì„ ìš”ì•½í•˜ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ë‹¤.\n"
                "ì‚¬ìš©ìžì™€ ìƒë‹´ê°€ì˜ ëŒ€í™”ë¥¼ ë³´ê³ , ìƒë‹´ íë¦„ì„ ì´í•´í•˜ê¸° ì‰¬ìš´ bullet í¬ì¸íŠ¸ë¡œ ì •ë¦¬í•œë‹¤."
            )
        ),
        HumanMessage(content=human_prompt),
    ]

    summary_ai = CHAT_LLM.invoke(messages_for_llm)
    # ì—¬ê¸°ì„œë„ summary_ai.contentê°€ listì¼ ê°€ëŠ¥ì„±ì€ ê±°ì˜ ì—†ì§€ë§Œ, ë°©ì–´ì ìœ¼ë¡œ ì²˜ë¦¬í•´ë„ ë¨
    return summary_ai.content if isinstance(summary_ai.content, str) else str(summary_ai.content)

# === counsel_prepare ===
#helper
def _select_candidate_techniques(state: State) -> List[str]:
    """
    ì´ë²ˆ í„´ì—ì„œ LLMì´ ì„ íƒí•  ìˆ˜ ìžˆëŠ” technique í›„ë³´ ë¦¬ìŠ¤íŠ¸ ìƒì„±.

    ê¸°ë³¸ ì •ì±…:
      - allowed_techniques ì „ì²´ë¥¼ ê¸°ë³¸ í›„ë³´ë¡œ ì‚¬ìš©
      - constraints.blocked_techniques í•­ëª©ì´ ìžˆìœ¼ë©´ ì œì™¸
      - technique_historyë¥¼ ì°¸ê³ í•´ ê³¼ë„í•˜ê²Œ ë°˜ë³µëœ ê¸°ë²•ì€ ìž„ì‹œ ì œì™¸
    """

    candidates = list(state.allowed_techniques or [])

    # 1) constraints ê¸°ë°˜ í•„í„°ë§
    constraints = state.constraints or {}
    blocked = constraints.get("blocked_techniques", []) or []
    if blocked:
        candidates = [tid for tid in candidates if tid not in blocked]

    # 2) ê°™ì€ ê¸°ë²•ì´ ë„ˆë¬´ ë°˜ë³µëœ ê²½ìš° ì œì™¸ (ì˜ˆ: 3ë²ˆ ì—°ì†)
    technique_history = state.technique_history or []
    if len(technique_history) >= 3:
        last_three = [h.get("technique_id") for h in technique_history[-3:]]
        if len(set(last_three)) == 1:  # ë§ˆì§€ë§‰ 3í„´ ëª¨ë‘ ê°™ì€ ê¸°ë²•ì´ë¼ë©´ overuse
            overused = last_three[0]
            candidates = [tid for tid in candidates if tid != overused]

    return candidates

#helper
def _build_rag_queries(state: State) -> List[str]:
    """
    CBT/CBD RAG ê²€ìƒ‰ì„ ìœ„í•œ ì¿¼ë¦¬ ë¬¸ìžì—´ì„ êµ¬ì„±.
    """

    queries: List[str] = []

    # 1) ì„¸ì…˜ ëª©í‘œ ê¸°ë°˜
    if state.session_goal:
        queries.append(f"CBT technique for goal: {state.session_goal}")

    # 2) core_task_tags ê¸°ë°˜
    if state.core_task_tags:
        merged_tags = " / ".join(state.core_task_tags)
        queries.append(f"CBT interventions for: {merged_tags}")

    # 3) ìµœê·¼ ì‚¬ìš©ìž ë°œí™” ê¸°ë°˜
    recent_utts: List[str] = []
    for msg in reversed(state.messages):
        if msg.type == "human":
            recent_utts.append(msg.content)
        if len(recent_utts) >= 3:
            break

    if recent_utts:
        combined = " ".join(recent_utts)
        queries.append(f"User situation: {combined[:300]}")

    return queries

#helper
def _retrieve_rag_snippets(queries: List[str], top_k_per_query: int = 4, max_snippets: int = 12) -> List[str]:
    """
    Pinecone ê¸°ë°˜ CBT/CBD RAGë¥¼ ì‹¤ì œë¡œ í˜¸ì¶œí•´ì„œ í…ìŠ¤íŠ¸ ìŠ¤ë‹ˆíŽ«ì„ ê°€ì ¸ì˜¨ë‹¤.

    - search_cbt_corpus(query, top_k)ë¥¼ í˜¸ì¶œí•œë‹¤ê³  ê°€ì •
        - ë°˜í™˜ê°’: LangChain Document ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ìœ ì‚¬í•œ dict ê°ì²´ ë¦¬ìŠ¤íŠ¸
        - ê° ê²°ê³¼ì—ì„œ content/text í•„ë“œë¥¼ êº¼ë‚´ì„œ ë¬¸ìžì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“ ë‹¤.
    - ë„¤ í”„ë¡œì íŠ¸ì—ì„œ ì‹¤ì œ RAG í•¨ìˆ˜ ì´ë¦„/ë°˜í™˜ íƒ€ìž…ì— ë§žê²Œ
      search_cbt_corpus í˜¸ì¶œ ë¶€ë¶„ê³¼ doc.content ì ‘ê·¼ ë¶€ë¶„ë§Œ ìˆ˜ì •í•˜ë©´ ëœë‹¤.
    """

    snippets: List[str] = []

    for query in queries:
        if not query.strip():
            continue

        try:
            # Pinecone RAG ê²€ìƒ‰ í•¨ìˆ˜
            docs = search_cbt_corpus(query=query, top_k=top_k_per_query)

            for doc in docs:
                # LangChain Document íƒ€ìž…ì´ë¼ê³  ê°€ì • (doc.page_content)
                # ë§Œì•½ dictë¡œ ë˜ì–´ ìžˆìœ¼ë©´ doc["content"]ì²˜ëŸ¼ ë°”ê¿”ì£¼ë©´ ë¨.
                text = getattr(doc, "page_content", None)
                if text is None and isinstance(doc, dict):
                    text = doc.get("content") or doc.get("text")

                if text:
                    snippets.append(text)

        except Exception as e:
            # RAG ì‹¤íŒ¨í•´ë„ ì „ì²´ í”Œë¡œìš°ê°€ í„°ì§€ì§€ ì•Šë„ë¡ ë°©ì–´
            print(f"[counsel_prepare] RAG ê²€ìƒ‰ ì¤‘ ì—ëŸ¬ ë°œìƒ (query={query!r}): {e}")

        # ì „ì²´ ìŠ¤ë‹ˆíŽ« ê°œìˆ˜ê°€ ë„ˆë¬´ ë§Žì•„ì§€ì§€ ì•Šë„ë¡ ì œí•œ
        if len(snippets) >= max_snippets:
            break

    return snippets[:max_snippets]

#node
def counsel_prepare(state: State) -> Dict[str, Any]:
    """
    Dynamic COUNSEL ë£¨í”„ì—ì„œ ë§¤ í„´ ì‹œìž‘ ì§ì „ì— ì‹¤í–‰ë˜ëŠ” ì¤€ë¹„ ë…¸ë“œ.
    
    ìˆ˜í–‰ ìž‘ì—…:
      - ì´ë²ˆ í„´ì—ì„œ LLMì´ ì„ íƒí•  ìˆ˜ ìžˆëŠ” candidate_techniques ê³„ì‚°
      - Pinecone RAGì— ì¿¼ë¦¬ ë‚ ë ¤ CBT/CBD ì´ë¡  ìŠ¤ë‹ˆíŽ«ì„ ê°€ì ¸ì˜¨ë‹¤.
      - ê²°ê³¼ë¥¼ state.candidate_techniques, state.rag_queries, state.rag_snippetsì— ë°˜ì˜í•œë‹¤.
    """

    print("\n=== [DEBUG] counsel_prepare Node Started ===")

    if state.phase != "COUNSEL":
        print(f"[counsel_prepare] phase != 'COUNSEL' (í˜„ìž¬: {state.phase!r}) â†’ ì—…ë°ì´íŠ¸ ì—†ìŒ")
        return {}

    updates: Dict[str, Any] = {}

    # 1) í›„ë³´ ê¸°ë²• ë¦¬ìŠ¤íŠ¸
    candidate_techniques = _select_candidate_techniques(state)
    if not candidate_techniques:
        print("[counsel_prepare] ê²½ê³ : candidate_techniquesê°€ ë¹„ì–´ ìžˆìŠµë‹ˆë‹¤. "
              "allowed_techniques ì „ì²´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        candidate_techniques = list(state.allowed_techniques or [])

    updates["candidate_techniques"] = candidate_techniques

    # 2) RAG ì¿¼ë¦¬ ìƒì„± + Pinecone ê²€ìƒ‰
    rag_queries = _build_rag_queries(state)
    rag_snippets = _retrieve_rag_snippets(rag_queries)

    # updates["rag_queries"] = rag_queries
    updates["rag_snippets"] = rag_snippets

    print("[counsel_prepare] candidate_techniques:", candidate_techniques)
    print("[counsel_prepare] rag_queries:", rag_queries)
    print(f"[counsel_prepare] rag_snippets_count={len(rag_snippets)}")

    return updates



# ======= selector ========
#helper
def _serialize_recent_messages(messages: List[BaseMessage], max_turns: int = 6) -> List[Dict[str, Any]]:
    """
    LLMì— ë„˜ê¸°ê¸° ì¢‹ë„ë¡ ìµœê·¼ ë©”ì‹œì§€ë¥¼ ë‹¨ìˆœ dict í˜•íƒœë¡œ ì§ë ¬í™”.
    - ì—­í• : "human"/"ai"
    - ë‚´ìš©: content í…ìŠ¤íŠ¸

    LangChain ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ë„˜ê²¨ë„ ë˜ì§€ë§Œ,
    í”„ë¡¬í”„íŠ¸ JSONì„ ê¹”ë”í•˜ê²Œ ë§Œë“¤ê³  ì‹¶ì–´ì„œ dictë¡œ ë³€í™˜.
    """
    recent: List[Dict[str, Any]] = []

    for msg in messages[-max_turns:]:
        role = "system"
        if msg.type == "human":
            role = "human"
        elif msg.type == "ai":
            role = "ai"

        recent.append(
            {
                "role": role,
                "content": msg.content,
            }
        )
    return recent

#node
def llm_technique_selector(state: State) -> Dict[str, Any]:
    print("\n=== [DEBUG] select_technique_llm Node Started ===")

    if state.phase != "COUNSEL":
        print(f"[select_technique_llm] phase != 'COUNSEL' (í˜„ìž¬: {state.phase!r}) â†’ ì—…ë°ì´íŠ¸ ì—†ìŒ")
        return {}

    updates: Dict[str, Any] = {}

    # 1) candidate_techniques í™•ë³´ (ì—†ìœ¼ë©´ allowed_techniquesë¡œ fallback)
    candidate_ids = state.candidate_techniques or state.allowed_techniques or []
    if not candidate_ids:
        print("[select_technique_llm] ê²½ê³ : candidate_techniquesì™€ allowed_techniquesê°€ ëª¨ë‘ ë¹„ì–´ ìžˆìŠµë‹ˆë‹¤.")
        return {}

    # 2) intervention.yaml ì¹´íƒˆë¡œê·¸ ë¡œë“œ
    catalog = load_techniques_catalog()

    candidate_defs: List[Dict[str, Any]] = []
    for tid in candidate_ids:
        meta = catalog.get(tid)
        if meta is None:
            print(f"[select_technique_llm] ê²½ê³ : intervention catalogì— ì—†ëŠ” technique_id: {tid!r}")
            continue
        candidate_defs.append(
            {
                "id": tid,
                **meta,
            }
        )

    if not candidate_defs:
        print("[select_technique_llm] ê²½ê³ : catalogì—ì„œ ìœ íš¨í•œ candidate_defsë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return {}

    # 3) ìµœê·¼ ë©”ì‹œì§€ ì§ë ¬í™”
    recent_messages = _serialize_recent_messages(state.messages)
    rag_snippets_preview = (state.rag_snippets or [])[:3]
    
    # 4) ì—¬ê¸°ì„œ prompt ë©”ì‹œì§€ ì§ì ‘ êµ¬ì„±
    system_content = (
        COMMON_IDENTITY
        + "\n\n"
        "ë„ˆëŠ” CBT ê¸°ë°˜ ì¶©ë™/ìŠµê´€ì  ì†Œë¹„ êµì •ì„ ë•ëŠ” ì „ë¬¸ ìƒë‹´ê°€ë‹¤.\n"
        "ì£¼ì–´ì§„ ì„¸ì…˜ ëª©í‘œ, core task, í›„ë³´ ê¸°ë²• ëª©ë¡, í˜„ìž¬ê¹Œì§€ì˜ ì§„í–‰ ìƒí™©, "
        "ì‚¬ìš©ìž ë°œí™”, RAG ìŠ¤ë‹ˆíŽ«ì„ ì¢…í•©í•´ ì´ë²ˆ í„´ì— ì‚¬ìš©í•  ê°€ìž¥ ì ì ˆí•œ CBT ê¸°ë²•ì„ í•˜ë‚˜ ì„ íƒí•˜ì—¬\n\n"
        "ì‚¬ìš©ìžê°€ ì„¸ì…˜ ëª©í‘œì— í•œ ê±¸ìŒ ë” ë‹¤ê°€ê°€ë„ë¡ ë•ëŠ” ìƒë‹´ ë©”ì‹œì§€ë¥¼ ìž‘ì„±í•˜ë¼."
        "ì‘ë‹µì€ ë°˜ë“œì‹œ TechniqueSelection ìŠ¤í‚¤ë§ˆì— ë§žëŠ” JSONìœ¼ë¡œ ë°˜í™˜í•´ì•¼ í•œë‹¤.\n"
        "TechniqueSelection ìŠ¤í‚¤ë§ˆëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n"
        "- technique_id: ì„ íƒí•œ CBT ê¸°ë²•ì˜ ID (ë¬¸ìžì—´)\n"
        "- micro_goal: ì´ë²ˆ í„´ì—ì„œ ë‹¬ì„±í•  êµ¬ì²´ì ì¸ ëª©í‘œ (ë¬¸ìžì—´)\n"
        "- reason: ì´ ì„ íƒì´ ì ì ˆí•œ ì´ìœ  (ë¬¸ìžì—´)\n\n"
        f"- ì„¸ì…˜ ëª©í‘œ(session_goal): {state.session_goal}\n"
        f"- ì„¸ì…˜ ëª©í‘œ(session_goal): {state.session_goal}\n"
        f"- í•µì‹¬ ìž‘ì—… íƒœê·¸(core_task_tags): {state.core_task_tags}\n"
        f"- ì„¸ì…˜ ì§„í–‰ë„(session_progress): {state.session_progress}\n"
        f"- ê¸°ë²• ì‚¬ìš© ížˆìŠ¤í† ë¦¬(technique_history): {state.technique_history}\n"
        f"- ì„¸ì…˜ ì œì•½(constraints): {state.constraints}\n"
        f"- RAG ì´ë¡  ìŠ¤ë‹ˆíŽ« ì¼ë¶€(rag_snippets): {state.rag_snippets[:3]}\n"
        f"- í›„ë³´ ê¸°ë²• ëª©ë¡(candidate_techniques): {candidate_defs}\n"
    )

    human_content = (
        "ì•„ëž˜ëŠ” ìµœê·¼ ëŒ€í™” ížˆìŠ¤í† ë¦¬ì•¼. ì‚¬ìš©ìžì˜ ìƒíƒœì™€ ì €í•­/íšŒí”¼, ì¸ì‚¬ì´íŠ¸ ìˆ˜ì¤€ì„ ê³ ë ¤í•´ì„œ "
        "ë„ˆë¬´ ë¬´ê²ì§€ ì•Šìœ¼ë©´ì„œë„ ì˜ë¯¸ ìžˆëŠ” í•œ ê±¸ìŒì„ ë§Œë“¤ ìˆ˜ ìžˆëŠ” CBT ê¸°ë²•ì„ í•˜ë‚˜ ê³¨ë¼ì¤˜.\n\n"
        f"ìµœê·¼ ëŒ€í™” ìš”ì•½(recent_messages): {recent_messages}\n\n"
        "ì´ë²ˆ í„´ì— ì‚¬ìš©í•  CBT ê¸°ë²•ê³¼ micro-goalì„ ê²°ì •í•´ì¤˜."
    )

    messages = [
        SystemMessage(content=system_content),
        HumanMessage(content=human_content),
    ]

    print("[select_technique_llm] LLM ë©”ì‹œì§€ ì¤€ë¹„ ì™„ë£Œ. candidate ê°œìˆ˜:", len(candidate_defs))

    # 5) LLM í˜¸ì¶œ (ì´ì œ messagesë¥¼ ë°”ë¡œ ë„£ìŒ)
    result = TECHNIQUE_SELECTOR.invoke(messages)

    # 6) ê²°ê³¼ í•´ì„ ë° ë°©ì–´ì  ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìž¬ì‚¬ìš©)
    technique_id = result.technique_id
    micro_goal = result.micro_goal
    reason = result.reason

    if not technique_id:
        print("[select_technique_llm] ê²½ê³ : LLMì´ technique_idë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return {}

    if technique_id not in catalog:
        print(f"[select_technique_llm] ê²½ê³ : LLMì´ ê³ ë¥¸ technique_id={technique_id!r}ê°€ catalogì— ì—†ìŠµë‹ˆë‹¤.")
        fallback_id = candidate_ids[0]
        technique_id = fallback_id
        reason = (reason or "") + "\n[FALLBACK] catalogì— ì—†ëŠ” ê¸°ë²•ì´ë¼ ì²« í›„ë³´ë¡œ ëŒ€ì²´."

    technique_meta = {
        "id": technique_id,
        **catalog[technique_id],
        "llm_reason": reason,
    }

    updates["selected_technique_id"] = technique_id
    updates["selected_technique_meta"] = technique_meta
    updates["micro_goal"] = micro_goal or ""

    print(f"[select_technique_llm] ì„ íƒëœ ê¸°ë²•: {technique_id}")
    print(f"[select_technique_llm] micro_goal: {updates['micro_goal']!r}")

    return updates


# ===== applier ======
#node
def llm_technique_applier(state: State) -> Dict[str, Any]:
    print("\n=== [DEBUG] llm_technique_applier Node Started ===")

    if state.phase != "COUNSEL":
        print(f"[applier] phase != 'COUNSEL' (í˜„ìž¬: {state.phase!r}) â†’ ìŠ¤í‚µ")
        return {}

    if not state.selected_technique_id:
        print("[applier] selected_technique_idê°€ ì—†ìŠµë‹ˆë‹¤. â†’ ìŠ¤í‚µ")
        return {}

    # 1) ìµœê·¼ ë©”ì‹œì§€ ì§ë ¬í™”
    recent_messages = _serialize_recent_messages(state.messages)

    # 2) System + Human ë©”ì‹œì§€ êµ¬ì„±
    system_content = (
        COMMON_IDENTITY
        + "\n\n"
        "ë„ˆëŠ” CBT ê¸°ë°˜ ì¶©ë™/ìŠµê´€ì  ì†Œë¹„ êµì •ì„ ë•ëŠ” ì „ë¬¸ ìƒë‹´ê°€ë‹¤.\n"
        "ì•„ëž˜ ì •ë³´ë¥¼ ì°¸ê³ í•˜ì—¬, ì´ë²ˆ í„´ì—ì„œ ì„ íƒëœ CBT ê¸°ë²•ì„ í™œìš©í•´ "
        "ì‚¬ìš©ìžê°€ ì„¸ì…˜ ëª©í‘œì— í•œ ê±¸ìŒ ë” ë‹¤ê°€ê°€ë„ë¡ ë•ëŠ” ìƒë‹´ ë©”ì‹œì§€ë¥¼ ìž‘ì„±í•˜ë¼.\n\n"
        "ì‘ë‹µì€ ë°˜ë“œì‹œ CounselorTurn ìŠ¤í‚¤ë§ˆì— ë§žëŠ” JSONìœ¼ë¡œ ë°˜í™˜í•´ì•¼ í•œë‹¤.\n\n"
        f"- ì„¸ì…˜ ëª©í‘œ(session_goal): {state.session_goal}\n"
        f"- í•µì‹¬ ìž‘ì—… íƒœê·¸(core_task_tags): {state.core_task_tags}\n"
        f"- ì„ íƒëœ ê¸°ë²•(selected_technique): {state.selected_technique_id}\n"
        f"- ì´ ê¸°ë²•ì˜ ì„¤ëª…(selected_technique_meta): {state.selected_technique_meta}\n"
        f"- RAG ì´ë¡  ìŠ¤ë‹ˆíŽ«(rag_snippets): {state.rag_snippets}\n"
        f"- ì„¸ì…˜ ì§„í–‰ë„(session_progress): {state.session_progress}\n"
        f"- ì´ë²ˆ í„´ì˜ micro_goal: {state.micro_goal}\n"
        f"- ì§€ê¸ˆê¹Œì§€ì˜ ìƒë‹´ ìš”ì•½(summary): {state.summary}\n"
        f"- ìµœê·¼ ëŒ€í™” ìš”ì•½(recent_messages):\n{recent_messages}\n"
    )

    last_user_input = ""
    if state.messages:
        last_msg = state.messages[-1]
        if getattr(last_msg, "type", "") == "human":
            content = last_msg.content
            if isinstance(content, list):
                parts = []
                for item in content:
                    if isinstance(item, dict) and item.get("type") == "text":
                        parts.append(item.get("text", ""))
                last_user_input = "\n".join(parts)
            else:
                last_user_input = content

    human_content = (
        "ìœ„ ì •ë³´ë¥¼ ì°¸ê³ í•´ì„œ, ì´ë²ˆ í„´ì—ì„œ ì‚¬ìš©í•  CBT ê¸°ë²•ì„ ì‹¤ì œë¡œ ì ìš©í•˜ëŠ” ìƒë‹´ ë©”ì‹œì§€ë¥¼ ìž‘ì„±í•´ì¤˜.\n"
        "ë©”ì‹œì§€ëŠ” ì‚¬ìš©ìžê°€ ë°”ë¡œ ì½ì„ ìˆ˜ ìžˆëŠ” í•œêµ­ì–´ ìƒë‹´ ë©˜íŠ¸ í˜•íƒœì—¬ì•¼ í•˜ê³ , "
        "CounselorTurn ìŠ¤í‚¤ë§ˆì— ë§žëŠ” JSONìœ¼ë¡œ ë°˜í™˜í•´ì•¼ í•´.\n\n"
        f"ì‚¬ìš©ìžì˜ ë§ˆì§€ë§‰ ë°œí™”: {last_user_input}"
    )

    messages = [
        SystemMessage(content=system_content),
        HumanMessage(content=human_content),
    ]

    # 3) LLM í˜¸ì¶œ (CounselorTurn êµ¬ì¡°)
    structured_output = LLM_CHAIN.invoke(messages)

    response_text = structured_output.response_text
    reasoning = structured_output.reasoning or ""
    progress_delta = structured_output.progress_delta or {}
    criteria_evals = structured_output.criteria_evaluations or []
    llm_suggest = structured_output.suggest_end_session
    llm_session_goals_met = structured_output.session_goals_met

    # 4) technique_history ì—…ë°ì´íŠ¸
    technique_history = list(state.technique_history or [])
    technique_history.append(
        {
            "technique_id": state.selected_technique_id,
            "micro_goal": state.micro_goal,
            "reasoning": reasoning,
        }
    )

    # 5) session_progress ì—…ë°ì´íŠ¸
    new_session_progress: Dict[str, Any] = dict(state.session_progress or {})
    # progress_delta ë°˜ì˜
    for key, value in progress_delta.items():
        new_session_progress[key] = value

    # turn_count += 1
    existing_turn_count = new_session_progress.get("turn_count", 0)
    try:
        existing_turn_count = int(existing_turn_count)
    except (TypeError, ValueError):
        existing_turn_count = 0
    new_session_progress["turn_count"] = existing_turn_count + 1

    # 6) criteria_status ì—…ë°ì´íŠ¸
    criteria_status: Dict[str, bool] = dict(state.criteria_status or {})
    for ev in criteria_evals:
        # CounselorTurn.CriterionEvaluation
        criteria_status[ev.criterion_id] = ev.met
        
    # 7) ì´ë²ˆ í„´ AI ë©”ì‹œì§€ ê°ì²´ ìƒì„±
    ai_message = AIMessage(content=response_text)

    # 8) ðŸ”¥ ìš”ì•½ ê°±ì‹  (summary í•„ë“œ ì—…ë°ì´íŠ¸)
    new_summary = _summarize_conversation(state, ai_message)

    print("ðŸ¤– [applier] LLM Response:")
    print(f"   - Technique: {state.selected_technique_id}")
    print(f"   - Micro goal: {state.micro_goal}")
    print(f"   - Reasoning: {reasoning}")
    print(f"   - Progress delta: {progress_delta}")
    print(f"   - Criteria evals: {[ (e.criterion_id, e.met) for e in criteria_evals ]}")
    print(f"   - turn_count -> {new_session_progress['turn_count']}")
    print(f"   - suggest_end_session: {llm_suggest}, session_goals_met: {llm_session_goals_met}")
    print(f"   - Assistant: {response_text[:120]}...")

    return {
        "messages": [AIMessage(content=response_text)],
        "llm_output": response_text,
        "technique_history": technique_history,
        "session_progress": new_session_progress,
        "criteria_status": criteria_status,
        "llm_suggest_end_session": llm_suggest,
        "summary": new_summary,
    }