# coach_agent/graph/build_prompt.py
import yaml
from ..state_types import State
from ..services import REPO

# ë­ì²´ì¸ ê´€ë ¨ ì„í¬íŠ¸
from langchain_core.prompts import (
    ChatPromptTemplate, 
    HumanMessagePromptTemplate, 
    MessagesPlaceholder,
    SystemMessagePromptTemplate # SystemMessage ëŒ€ì‹  í…œí”Œë¦¿ìš© í´ë˜ìŠ¤ ì‚¬ìš© ê¶Œì¥
)
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage

# [Refactoring] í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ í…œí”Œë¦¿ ê°€ì ¸ì˜¤ê¸°
# (ê°™ì€ í´ë”ì— prompts.pyê°€ ìˆë‹¤ê³  ê°€ì •)
from .prompts import (
    TEMPLATE_GREETING_NEW_USER,
    TEMPLATE_GREETING_WEEKLY,
    TEMPLATE_GREETING_GENERAL,
    TEMPLATE_CONVERSATION
)

# --- í—¬í¼ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ìœ ì§€) ---
def _clean_message_content(msg: BaseMessage) -> BaseMessage:
    content_val = msg.content
    if isinstance(content_val, list):
        text_content = ""
        for item in content_val:
            if isinstance(item, dict) and item.get("type") == "text":
                text_content = item.get("text", "")
                break 
        content_val = text_content
    if not isinstance(content_val, str):
        content_val = str(content_val)
    if msg.type == "human":
        return HumanMessage(content=content_val)
    elif msg.type == "ai":
        return AIMessage(content=content_val)
    elif msg.type == "system":
        return SystemMessage(content=content_val)
    else:
        msg.content = content_val
        return msg

def _load_past_summaries(user_id: str, current_week: int) -> list:
    history = []
    past_summaries = REPO.get_past_summaries(user_id, current_week)
    for summary in past_summaries:
        summary_text = f"--- ì§€ë‚œ {summary['week']}ì£¼ì°¨ ìš”ì•½ ---\n{summary['summary']}"
        history.append(AIMessage(content=summary_text))
    return history

# --- build_prompt í•¨ìˆ˜ ---
def build_prompt(state: State) -> dict:
    spec = state.protocol
    session_type = state.session_type

    # 1. ì²« í„´(ì¸ì‚¬)ì¸ì§€ í™•ì¸
    is_first_turn = state.last_user_message is None
    prompt_messages = [] 

    if is_first_turn:
        # --- 1-A. ì²« í„´ì¼ ê²½ìš° (ì¸ì‚¬ë§ ìƒì„±) ---
        nickname = state.nickname
        days_since = state.days_since_last_seen

        if nickname is None:
            # (1) ì‹ ê·œ ì‚¬ìš©ì
            prompt_template = ChatPromptTemplate.from_template(TEMPLATE_GREETING_NEW_USER)
            variables = {
            }
            
        elif session_type == "WEEKLY":
            # (2) ì£¼ê°„ ìƒë‹´ ì‹œì‘
            seed_data = spec.get("prompt_seed", ["ì˜¤ëŠ˜ ì–´ë– ì…¨ë‚˜ìš”?"]) 
            if isinstance(seed_data, str):
                seed_data = [seed_data]
                
            prompt_template = ChatPromptTemplate.from_template(TEMPLATE_GREETING_WEEKLY)
            variables = {
                "nickname": nickname,
                "days_since_last_seen": days_since,
                "session_type": "WEEKLY",
                "week": spec.get("week", state.current_week),
                "title": spec.get("title", "ì£¼ê°„ ìƒë‹´"),
                "goals": "; ".join(spec.get("goals", [])),
                "prompt_seed": seed_data[0],
            }
            
        elif session_type == "GENERAL":
            # (3) ìƒë‹´ ì™„ë£Œ í›„ ì¬ì§„ì…
            prompt_template = ChatPromptTemplate.from_template(TEMPLATE_GREETING_GENERAL)
            variables = {"nickname": nickname}
        
        else:
            # (4) Fallback
            prompt_template = ChatPromptTemplate.from_template(
                "ì•ˆë…•í•˜ì„¸ìš”! ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?\n\n[ì¤‘ìš”] **ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.**"
            )
            variables = {}

        prompt_messages = prompt_template.invoke(variables).to_messages()

    else:
        # --- 1-B. ëŒ€í™” ì¤‘ì¼ ê²½ìš° (Conversation Loop) ---
        level = state.intervention_level or "L1"
        
        intervention_instruction = ""
        empathy_instruction = "Briefly acknowledge the user's feeling."

        # [ë ˆë²¨ë³„ ë¶„ê¸° ë¡œì§]
        if level in ["L4", "L5"]:
            intervention_instruction = """
            ğŸš¨ **EMERGENCY / HIGH RISK DETECTED** ğŸš¨
            The user is showing signs of severe depression.
            1. Suggest professional help gently.
            2. Gently steer them back to the topic.
            """
            empathy_instruction = "Show deep empathy and validate their pain heavily."
        
        elif level in ["L2", "L3"]:
            intervention_instruction = """
            âš ï¸ **AVOIDANCE DETECTED** âš ï¸
            Redirect immediately to the 'Script Steps'.
            """
            empathy_instruction = "Briefly acknowledge, but prioritize the session goal."
        
        else: # L1
            intervention_instruction = "Proceed with the standard CBT coaching flow."
            empathy_instruction = "Show empathy and acknowledge the Human's last message."

        # ë°ì´í„° ì¤€ë¹„
        cleaned_chat_history = [_clean_message_content(msg) for msg in state.messages]
        past_summaries = _load_past_summaries(state.user_id, state.current_week)
        exit_criteria_text = yaml.dump(spec.get("exit_criteria", {}), allow_unicode=True)

        variables = {
            "week": spec.get("week", state.current_week),
            "title": spec.get("title", "Daily Check-in"),
            "goals": "; ".join(spec.get("goals", [])),
            "steps": " â†’ ".join(spec.get("script_steps", [])),
            "level": level,
            "exit_goals": exit_criteria_text,
            # historyëŠ” placeholderë¡œ ë“¤ì–´ê°€ë¯€ë¡œ ë³€ìˆ˜ì—ì„œ ì œì™¸í•˜ê±°ë‚˜ textë¡œ ë„£ì§€ ì•ŠìŒ
            "user_message": state.last_user_message,
            "intervention_instruction": intervention_instruction,
            "empathy_instruction": empathy_instruction
        }
        
        # [ìˆ˜ì •] SystemMessage ì•ˆì— ë³€ìˆ˜ê°€ ìˆìœ¼ë¯€ë¡œ SystemMessagePromptTemplate ì‚¬ìš© ê¶Œì¥
        prompt_template = ChatPromptTemplate.from_messages([
            SystemMessagePromptTemplate.from_template(TEMPLATE_CONVERSATION),
            MessagesPlaceholder(variable_name="history"),
            HumanMessagePromptTemplate.from_template("{user_message}"),
        ])
        
        # historyëŠ” invoke ì‹œì— ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¡œ ì£¼ì…
        invoke_vars = variables.copy()
        invoke_vars["history"] = past_summaries + cleaned_chat_history
        
        prompt_messages = prompt_template.invoke(invoke_vars).to_messages()
    
    return {
        "llm_prompt_messages": prompt_messages
    }