# coach_agent/graph/run_llm.py
from coach_agent.graph.state import State
from coach_agent.services.llm import LLM_CHAIN
from coach_agent.services import REPO
from langchain_core.messages import AIMessage # í›„ì²˜ë¦¬ ë…¸ë“œ ì‚¬ìš© ì‹œ ì‚­ì œ


def run_llm(state: State) -> dict:
    print(f"\n=== [DEBUG] RunLLM Node Started ===")
    
    # 1. ì•ˆì „ì¥ì¹˜: í”„ë¡¬í”„íŠ¸ê°€ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€
    if not state.llm_prompt_messages:
        print("â© [RunLLM] í”„ë¡¬í”„íŠ¸ ì—†ìŒ -> ìŠ¤í‚µ")
        return {
            "llm_output": None,
            "exit": False
        }
    
    # 2. LLM í˜¸ì¶œ
    structured_output = LLM_CHAIN.invoke(state.llm_prompt_messages)
    
    # 3. [Progress] ë‹¨ê³„ ì´ë™ ë¡œì§
    llm_decided_step = structured_output.current_step_index
    current_idx = getattr(state, "current_step_index", 0) # 0ë¶€í„° ì‹œì‘ ê°€ì •
    
    new_step_idx = current_idx
    
    if llm_decided_step > current_idx:
        new_step_idx = llm_decided_step
        print(f"â© [Progress] ë‹¨ê³„ ì´ë™: {current_idx} -> {new_step_idx}")
        
        # [í•µì‹¬] DB ì €ì¥ ì‹œë„ (ì—ëŸ¬ í•¸ë“¤ë§ ì¶”ê°€)
        try:
            REPO.update_checkpoint(state.user_id, state.current_week, new_step_idx)
            print(f"ğŸ’¾ [DB Save] ì €ì¥ ì„±ê³µ: Step {new_step_idx}")
        except Exception as e:
            print(f"ğŸ”¥ [DB Save Error] ì €ì¥ ì‹¤íŒ¨: {e}")
            
    else:
        # (ì„ íƒ) ìœ ì§€ë  ë•Œë„ í™•ì‹¤íˆ í•˜ê¸° ìœ„í•´ ì €ì¥í•  ìˆ˜ ìˆìŒ
        new_step_idx = current_idx
        print(f"âš“ [Progress] ë‹¨ê³„ ìœ ì§€: {current_idx}")
        
    # 4. [Metrics] ì†ë§ˆìŒ ë…¸íŠ¸ ì—…ë°ì´íŠ¸
    # ê¸°ì¡´ metricsë¥¼ ë³µì‚¬í•œ ë’¤, ìƒˆë¡œìš´ ê·¼ê±°ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
    new_metrics = state.metrics.copy()
    if structured_output.reasoning:
        new_metrics["exit_reasoning"] = structured_output.reasoning
    
    # --- ë””ë²„ê¹… ì¶œë ¥ ---
    print(f"ğŸ¤– LLM Response:")
    print(f"   - Step: {new_step_idx}")
    print(f"   - Goals Met?: {structured_output.session_goals_met}")
    print(f"   - Reasoning: {structured_output.reasoning}")
    print(f"   - Assistant: {structured_output.response_text}...")
    # ------------------

    # 5. ìµœì¢… ë°˜í™˜ (ì—¬ê¸°ì„œ ë¦¬í„´í•œ ê°’ì´ Stateì— ë°˜ì˜ë©ë‹ˆë‹¤)
    return {
        "messages": [AIMessage(content=structured_output.response_text)],  # í›„ì²˜ë¦¬ ë…¸ë“œ ì‚¬ìš© ì‹œ ì‚­ì œ
        "current_step_index": new_step_idx,   # ë‹¨ê³„ ì—…ë°ì´íŠ¸
        "exit": structured_output.session_goals_met,
        "llm_output": structured_output.response_text,
        "metrics": new_metrics                # metrics ì—…ë°ì´íŠ¸
    }